{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "750e5b28",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Roaming\\Python\\Python38\\site-packages\\gensim\\similarities\\__init__.py:15: UserWarning: The gensim.similarities.levenshtein submodule is disabled, because the optional Levenshtein package <https://pypi.org/project/python-Levenshtein/> is unavailable. Install Levenhstein (e.g. `pip install python-Levenshtein`) to suppress this warning.\n",
      "  warnings.warn(msg)\n"
     ]
    }
   ],
   "source": [
    "# Data Preprocessing Package\n",
    "import re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "# NLP Package\n",
    "from konlpy.tag import *  \n",
    "    #영어가 아니므로, 일단 불필요\n",
    "\n",
    "#설치 안 되어 있으면, conda CLI에서 pip install gensim\n",
    "import gensim\n",
    "import gensim.corpora as corpora\n",
    "from gensim.models import CoherenceModel\n",
    "from gensim import models\n",
    "from collections import Counter\n",
    "\n",
    "# Visualization Package\n",
    "# 설치가 안되어 있으면, 역시 conda CLI에서 pip install pyLDAvis\n",
    "import pyLDAvis\n",
    "import pyLDAvis.gensim_models\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "#from konlpy.tag import Okt\n",
    "\n",
    "from pprint import pprint\n",
    "import itertools\n",
    "import math\n",
    "\n",
    "import logging\n",
    "logging.basicConfig(format='%(asctime)s : %(levelname)s : %(message)s', level=logging.ERROR)\n",
    " \n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\",category=DeprecationWarning)\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from sklearn.feature_extraction.text import ENGLISH_STOP_WORDS as sklearn_stop_words\n",
    "from nltk.tag import pos_tag\n",
    "lemma = WordNetLemmatizer()\n",
    "import nltk\n",
    "#Data Preprocessing Package\n",
    "import re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import nltk\n",
    "from nltk.tokenize import TreebankWordTokenizer\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.tag import pos_tag\n",
    "\n",
    "from sklearn.feature_extraction.text import ENGLISH_STOP_WORDS as sklearn_stop_words\n",
    "import re\n",
    "import nltk\n",
    "#from nltk.tokenize import TreebankWordTokenizer\n",
    "from nltk.tokenize import WordPunctTokenizer \n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.tag import pos_tag\n",
    "\n",
    "from sklearn.feature_extraction.text import ENGLISH_STOP_WORDS as sklearn_stop_words\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "882d724b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df=df=pd.read_excel('./Data/esg전처리.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4de9b354",
   "metadata": {},
   "outputs": [],
   "source": [
    "del df['Unnamed: 0']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "75738108",
   "metadata": {},
   "outputs": [],
   "source": [
    "df=df.set_index('firmname')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d580757a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>subtitle</th>\n",
       "      <th>new_split</th>\n",
       "      <th>cleaned</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>firmname</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1.samsung_electronic2021.txt</th>\n",
       "      <td>5</td>\n",
       "      <td>\\nCorporate Governance \\nUnder the principle o...</td>\n",
       "      <td>['governance', 'principle', 'transparent', 'bu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NaN</th>\n",
       "      <td>6</td>\n",
       "      <td>\\nCompliance &amp; Ethics \\nCompliance Management ...</td>\n",
       "      <td>['compliance', 'compliance', 'management', 'sa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NaN</th>\n",
       "      <td>7</td>\n",
       "      <td>\\nSteps Taken to Strengthen Compliance  \\nin 2...</td>\n",
       "      <td>['compliance', 'compliance', 'independence', '...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NaN</th>\n",
       "      <td>8</td>\n",
       "      <td>\\nBusiness Sustainability CE Consumer Electro...</td>\n",
       "      <td>['business', 'sustainability', 'consumer', 'di...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NaN</th>\n",
       "      <td>9</td>\n",
       "      <td>\\nApproach to Sustainability\\n16 Sustainabilit...</td>\n",
       "      <td>['approach', 'sustainability', 'sustainability...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NaN</th>\n",
       "      <td>13</td>\n",
       "      <td>HR System and Talents Development \\n Spirit \\n...</td>\n",
       "      <td>['development', 'spirit', 'pride', 'relentless...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NaN</th>\n",
       "      <td>14</td>\n",
       "      <td>Human Rights \\n Principle of Halla Holdings \\n...</td>\n",
       "      <td>['principle', 'halla', 'company', 'respect', '...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NaN</th>\n",
       "      <td>15</td>\n",
       "      <td>Social Contribution and Communication \\n Socia...</td>\n",
       "      <td>['contribution', 'communication', 'contributio...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NaN</th>\n",
       "      <td>16</td>\n",
       "      <td>Safety &amp; Health \\n Policies on Workers’ Safety...</td>\n",
       "      <td>['safety', 'health', 'safety', 'health', 'inho...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NaN</th>\n",
       "      <td>17</td>\n",
       "      <td>Environment \\n SUSTAINABILITY FACTBOOK \\n ESG ...</td>\n",
       "      <td>['environment', 'sustainability', 'performance...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1680 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                             subtitle  \\\n",
       "firmname                                \n",
       "1.samsung_electronic2021.txt        5   \n",
       "NaN                                 6   \n",
       "NaN                                 7   \n",
       "NaN                                 8   \n",
       "NaN                                 9   \n",
       "...                               ...   \n",
       "NaN                                13   \n",
       "NaN                                14   \n",
       "NaN                                15   \n",
       "NaN                                16   \n",
       "NaN                                17   \n",
       "\n",
       "                                                                      new_split  \\\n",
       "firmname                                                                          \n",
       "1.samsung_electronic2021.txt  \\nCorporate Governance \\nUnder the principle o...   \n",
       "NaN                           \\nCompliance & Ethics \\nCompliance Management ...   \n",
       "NaN                           \\nSteps Taken to Strengthen Compliance  \\nin 2...   \n",
       "NaN                            \\nBusiness Sustainability CE Consumer Electro...   \n",
       "NaN                           \\nApproach to Sustainability\\n16 Sustainabilit...   \n",
       "...                                                                         ...   \n",
       "NaN                           HR System and Talents Development \\n Spirit \\n...   \n",
       "NaN                           Human Rights \\n Principle of Halla Holdings \\n...   \n",
       "NaN                           Social Contribution and Communication \\n Socia...   \n",
       "NaN                           Safety & Health \\n Policies on Workers’ Safety...   \n",
       "NaN                           Environment \\n SUSTAINABILITY FACTBOOK \\n ESG ...   \n",
       "\n",
       "                                                                        cleaned  \n",
       "firmname                                                                         \n",
       "1.samsung_electronic2021.txt  ['governance', 'principle', 'transparent', 'bu...  \n",
       "NaN                           ['compliance', 'compliance', 'management', 'sa...  \n",
       "NaN                           ['compliance', 'compliance', 'independence', '...  \n",
       "NaN                           ['business', 'sustainability', 'consumer', 'di...  \n",
       "NaN                           ['approach', 'sustainability', 'sustainability...  \n",
       "...                                                                         ...  \n",
       "NaN                           ['development', 'spirit', 'pride', 'relentless...  \n",
       "NaN                           ['principle', 'halla', 'company', 'respect', '...  \n",
       "NaN                           ['contribution', 'communication', 'contributio...  \n",
       "NaN                           ['safety', 'health', 'safety', 'health', 'inho...  \n",
       "NaN                           ['environment', 'sustainability', 'performance...  \n",
       "\n",
       "[1680 rows x 3 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a90b412b",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = Okt() \n",
    "stop_words=nltk.corpus.stopwords.words('english')\n",
    "stop_words=list(set(stop_words).union(set(sklearn_stop_words)))\n",
    "tokenizer=WordPunctTokenizer()\n",
    "lemma = WordNetLemmatizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "6e028a54",
   "metadata": {},
   "outputs": [],
   "source": [
    "st=pd.read_csv('./Data/불용어.txt', sep = \"\\t\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f29ad3e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "remove_bracket=['step','report','reporting','halla','park','youngmi','audit','aver','busi']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "8e041ee8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>불용어</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>caf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>overview</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>content</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>cafe</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>menu</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>caf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>krw</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>billion</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>corporate</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>part</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>introduction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>message</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>letters</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>pillar</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>chilgokjungangdaero</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>cpp</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>ext</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>fefree</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>chargedischarge</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>cheoyongro</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>appendix</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>overview</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>area</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>index</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>factbook</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>group</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    불용어\n",
       "0                   caf\n",
       "1              overview\n",
       "2               content\n",
       "3                 cafe \n",
       "4                  menu\n",
       "5                   caf\n",
       "6                   krw\n",
       "7               billion\n",
       "8             corporate\n",
       "9                  part\n",
       "10         introduction\n",
       "11              message\n",
       "12              letters\n",
       "13               pillar\n",
       "14  chilgokjungangdaero\n",
       "15                  cpp\n",
       "16                  ext\n",
       "17               fefree\n",
       "18      chargedischarge\n",
       "19           cheoyongro\n",
       "20             appendix\n",
       "21             overview\n",
       "22                 area\n",
       "23                index\n",
       "24             factbook\n",
       "25                group"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "st"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "ede98315",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in st.불용어:\n",
    "    remove_bracket.append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "a75b2f59",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['step',\n",
       " 'report',\n",
       " 'reporting',\n",
       " 'halla',\n",
       " 'park',\n",
       " 'youngmi',\n",
       " 'audit',\n",
       " 'aver',\n",
       " 'busi',\n",
       " 'caf',\n",
       " 'caf',\n",
       " 'caf',\n",
       " 'overview',\n",
       " 'content',\n",
       " 'cafe ',\n",
       " 'menu',\n",
       " 'caf',\n",
       " 'krw',\n",
       " 'billion',\n",
       " 'corporate',\n",
       " 'part',\n",
       " 'introduction',\n",
       " 'message',\n",
       " 'letters',\n",
       " 'pillar',\n",
       " 'chilgokjungangdaero',\n",
       " 'cpp',\n",
       " 'ext',\n",
       " 'fefree',\n",
       " 'chargedischarge',\n",
       " 'cheoyongro',\n",
       " 'appendix',\n",
       " 'overview',\n",
       " 'area',\n",
       " 'index',\n",
       " 'factbook',\n",
       " 'group']"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "remove_bracket"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "d1649320",
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words.extend(remove_bracket)\n",
    "sep = \"\\n\" # 불용어 처리 인자\n",
    "len(stop_words)\n",
    "def prepro(text):\n",
    "\n",
    "    a=text.lower()\n",
    "    a=re.sub('\\n',' ',a)\n",
    "    a=re.sub('\\r',' ',a)\n",
    "    a=re.sub('\\t',' ',a)\n",
    "    a=re.sub('x0002','',a)\n",
    "    b = re.sub('[^a-zA-Z ]','',a).strip()\n",
    "\n",
    "    tagged_list = pos_tag(tokenizer.tokenize(b))\n",
    "    ad_and_nouns = [t[0] for t in tagged_list if (t[1] == \"NN\")or(t[1]==\"NNP\")or(t[1]=='JJ'))]\n",
    "    e_list= [lemma.lemmatize(i) for i in ad_and_nouns]\n",
    "    result=[w for w in e_list if (w not in stop_words) and  (len(w) > 2)]\n",
    "    # remove single character\n",
    "\n",
    "    return result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "fe03ad3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "raw=list(df['new_split'])\n",
    "\n",
    "cleaned=[' '. join(prepro(i)) for i in raw]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "db56e689",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>subtitle</th>\n",
       "      <th>new_split</th>\n",
       "      <th>cleaned</th>\n",
       "      <th>newclean</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>firmname</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1.samsung_electronic2021.txt</th>\n",
       "      <td>5</td>\n",
       "      <td>\\nCorporate Governance \\nUnder the principle o...</td>\n",
       "      <td>['governance', 'principle', 'transparent', 'bu...</td>\n",
       "      <td>governance principle transparent business boar...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NaN</th>\n",
       "      <td>6</td>\n",
       "      <td>\\nCompliance &amp; Ethics \\nCompliance Management ...</td>\n",
       "      <td>['compliance', 'compliance', 'management', 'sa...</td>\n",
       "      <td>compliance compliance management samsung compl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NaN</th>\n",
       "      <td>7</td>\n",
       "      <td>\\nSteps Taken to Strengthen Compliance  \\nin 2...</td>\n",
       "      <td>['compliance', 'compliance', 'independence', '...</td>\n",
       "      <td>compliance compliance independence authority c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NaN</th>\n",
       "      <td>8</td>\n",
       "      <td>\\nBusiness Sustainability CE Consumer Electro...</td>\n",
       "      <td>['business', 'sustainability', 'consumer', 'di...</td>\n",
       "      <td>business sustainability consumer division trus...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NaN</th>\n",
       "      <td>9</td>\n",
       "      <td>\\nApproach to Sustainability\\n16 Sustainabilit...</td>\n",
       "      <td>['approach', 'sustainability', 'sustainability...</td>\n",
       "      <td>approach sustainability sustainability sustain...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NaN</th>\n",
       "      <td>13</td>\n",
       "      <td>HR System and Talents Development \\n Spirit \\n...</td>\n",
       "      <td>['development', 'spirit', 'pride', 'relentless...</td>\n",
       "      <td>development spirit pride relentless challenge ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NaN</th>\n",
       "      <td>14</td>\n",
       "      <td>Human Rights \\n Principle of Halla Holdings \\n...</td>\n",
       "      <td>['principle', 'halla', 'company', 'respect', '...</td>\n",
       "      <td>principle company respect groupwide vision com...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NaN</th>\n",
       "      <td>15</td>\n",
       "      <td>Social Contribution and Communication \\n Socia...</td>\n",
       "      <td>['contribution', 'communication', 'contributio...</td>\n",
       "      <td>contribution communication contribution vision...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NaN</th>\n",
       "      <td>16</td>\n",
       "      <td>Safety &amp; Health \\n Policies on Workers’ Safety...</td>\n",
       "      <td>['safety', 'health', 'safety', 'health', 'inho...</td>\n",
       "      <td>safety health safety health inhouse worksite s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NaN</th>\n",
       "      <td>17</td>\n",
       "      <td>Environment \\n SUSTAINABILITY FACTBOOK \\n ESG ...</td>\n",
       "      <td>['environment', 'sustainability', 'performance...</td>\n",
       "      <td>environment sustainability performance gri ass...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1680 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                             subtitle  \\\n",
       "firmname                                \n",
       "1.samsung_electronic2021.txt        5   \n",
       "NaN                                 6   \n",
       "NaN                                 7   \n",
       "NaN                                 8   \n",
       "NaN                                 9   \n",
       "...                               ...   \n",
       "NaN                                13   \n",
       "NaN                                14   \n",
       "NaN                                15   \n",
       "NaN                                16   \n",
       "NaN                                17   \n",
       "\n",
       "                                                                      new_split  \\\n",
       "firmname                                                                          \n",
       "1.samsung_electronic2021.txt  \\nCorporate Governance \\nUnder the principle o...   \n",
       "NaN                           \\nCompliance & Ethics \\nCompliance Management ...   \n",
       "NaN                           \\nSteps Taken to Strengthen Compliance  \\nin 2...   \n",
       "NaN                            \\nBusiness Sustainability CE Consumer Electro...   \n",
       "NaN                           \\nApproach to Sustainability\\n16 Sustainabilit...   \n",
       "...                                                                         ...   \n",
       "NaN                           HR System and Talents Development \\n Spirit \\n...   \n",
       "NaN                           Human Rights \\n Principle of Halla Holdings \\n...   \n",
       "NaN                           Social Contribution and Communication \\n Socia...   \n",
       "NaN                           Safety & Health \\n Policies on Workers’ Safety...   \n",
       "NaN                           Environment \\n SUSTAINABILITY FACTBOOK \\n ESG ...   \n",
       "\n",
       "                                                                        cleaned  \\\n",
       "firmname                                                                          \n",
       "1.samsung_electronic2021.txt  ['governance', 'principle', 'transparent', 'bu...   \n",
       "NaN                           ['compliance', 'compliance', 'management', 'sa...   \n",
       "NaN                           ['compliance', 'compliance', 'independence', '...   \n",
       "NaN                           ['business', 'sustainability', 'consumer', 'di...   \n",
       "NaN                           ['approach', 'sustainability', 'sustainability...   \n",
       "...                                                                         ...   \n",
       "NaN                           ['development', 'spirit', 'pride', 'relentless...   \n",
       "NaN                           ['principle', 'halla', 'company', 'respect', '...   \n",
       "NaN                           ['contribution', 'communication', 'contributio...   \n",
       "NaN                           ['safety', 'health', 'safety', 'health', 'inho...   \n",
       "NaN                           ['environment', 'sustainability', 'performance...   \n",
       "\n",
       "                                                                       newclean  \n",
       "firmname                                                                         \n",
       "1.samsung_electronic2021.txt  governance principle transparent business boar...  \n",
       "NaN                           compliance compliance management samsung compl...  \n",
       "NaN                           compliance compliance independence authority c...  \n",
       "NaN                           business sustainability consumer division trus...  \n",
       "NaN                           approach sustainability sustainability sustain...  \n",
       "...                                                                         ...  \n",
       "NaN                           development spirit pride relentless challenge ...  \n",
       "NaN                           principle company respect groupwide vision com...  \n",
       "NaN                           contribution communication contribution vision...  \n",
       "NaN                           safety health safety health inhouse worksite s...  \n",
       "NaN                           environment sustainability performance gri ass...  \n",
       "\n",
       "[1680 rows x 4 columns]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['newclean']=cleaned\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "93315e23",
   "metadata": {},
   "outputs": [],
   "source": [
    "stopword_vocab = stop_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "9d724ddd",
   "metadata": {},
   "outputs": [],
   "source": [
    "result_data = [ i.split() for i in df['newclean']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "a52828ff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1680"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(result_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cc8006a",
   "metadata": {},
   "outputs": [],
   "source": [
    "###전처리 다하고 단어만 따로 삭제할 때###\n",
    "\n",
    "t1= [ i.split() for i in df['newclean']]\n",
    "removes=['ceo','dear']\n",
    "for a in t1:\n",
    "    for words in a:\n",
    "        if words in removes:\n",
    "            a.remove(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "aaa0b630",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "전체 워드의 개수 : 701334\n",
      "              text  count\n",
      "0       management  26137\n",
      "1         business  12921\n",
      "2           safety   9283\n",
      "3          company   7027\n",
      "4      information   6584\n",
      "5             risk   6189\n",
      "6      environment   5041\n",
      "7        committee   4890\n",
      "8           health   4819\n",
      "9   sustainability   4797\n",
      "10     performance   4778\n",
      "11          energy   4710\n",
      "12      compliance   4699\n",
      "13        training   4616\n",
      "14         support   4479\n",
      "15        customer   4145\n",
      "16     development   4116\n",
      "17         quality   4015\n",
      "18          growth   3987\n",
      "19         process   3949\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def word_corpus(result_data):\n",
    "    #전체 단어의 갯수 파악\n",
    "    words = list(itertools.chain(*result_data))\n",
    "    print('전체 워드의 개수 : {}'.format(len(words)))\n",
    "\n",
    "    #단어의 빈도수를 확인 후 추가할 불용어 확인 작업\n",
    "    vocab = Counter(words)\n",
    "    vocab_size = len(words)\n",
    "    vocab = vocab.most_common(vocab_size) # 등장 빈도수가 높은 상위 n개의 단어만 저장 vocab\n",
    "    return vocab\n",
    "\n",
    "vocab=word_corpus(result_data)\n",
    "\n",
    "# 전체 워드의 빈도 계수 \n",
    "df_corpus=pd.DataFrame(columns=[\"text\",\"count\"])\n",
    "tmp_list=[]\n",
    "tmp_list1=[]\n",
    "for word, num in vocab:\n",
    "    tmp_list.append(word)\n",
    "    tmp_list1.append(num)\n",
    "df_corpus['text']=tmp_list\n",
    "df_corpus['count']=tmp_list1\n",
    "#상위 20개의 워드 카운드 계수만 출력\n",
    "print(df_corpus.head(20))\n",
    "\n",
    "# 토픽 모델링 딕셔너리 생성\n",
    "id2word = corpora.Dictionary(result_data)\n",
    " \n",
    "# 토픽모델링에 사용할 말뭉치 생성\n",
    "texts = result_data\n",
    " \n",
    "# 용어-문서 빈도\n",
    "corpus = [id2word.doc2bow(text) for text in texts]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "b9153ca0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.util import ngrams\n",
    "full_gram=[]\n",
    "tmp=[i.split() for i in df.newclean.to_list()]\n",
    "for k in tmp:\n",
    "    two_grams = list(ngrams(k,2))\n",
    "    #print(two_grams)\n",
    "    two_gram_list=[\" \".join(x) for x in two_grams]\n",
    "    full_gram.append(two_gram_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "760b9068",
   "metadata": {},
   "outputs": [],
   "source": [
    "def flatten(l):\n",
    "    flatlist=[]\n",
    "    for elem in l:\n",
    "        if type(elem) ==list:\n",
    "            for e in elem:\n",
    "                flatlist.append(e)\n",
    "        else:\n",
    "            flatlist.append(elem)\n",
    "    return flatlist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "ec9ee83f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "full_bigram=flatten(full_gram)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "582420f9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1680"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(full_gram)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "45e2363e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "699654"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(full_bigram)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "671b2875",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "risk management              2454\n",
      "safety health                2034\n",
      "sustainability management    1425\n",
      "supply chain                 1300\n",
      "information security         1239\n",
      "information protection       1190\n",
      "climate change               1171\n",
      "safety management            1167\n",
      "management management        1115\n",
      "health safety                1027\n",
      "customer satisfaction         886\n",
      "management committee          836\n",
      "greenhouse gas                745\n",
      "quality management            726\n",
      "code conduct                  609\n",
      "health management             607\n",
      "compliance management         551\n",
      "consumer protection           529\n",
      "business management           489\n",
      "management business           487\n",
      "management risk               474\n",
      "environment safety            474\n",
      "management safety             473\n",
      "value chain                   465\n",
      "power generation              461\n",
      "energy consumption            443\n",
      "work environment              429\n",
      "business site                 419\n",
      "management compliance         414\n",
      "business business             407\n",
      "dtype: int64 "
     ]
    }
   ],
   "source": [
    "flatten_bigram=pd.Series([x for x in full_bigram if len(x)>2])\n",
    "print(flatten_bigram.value_counts().head(30), end=\" \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "f716d9e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "전체 워드의 개수 : 699654\n",
      "                         text  count\n",
      "0             risk management   2454\n",
      "1               safety health   2034\n",
      "2   sustainability management   1425\n",
      "3                supply chain   1300\n",
      "4        information security   1239\n",
      "5      information protection   1190\n",
      "6              climate change   1171\n",
      "7           safety management   1167\n",
      "8       management management   1115\n",
      "9               health safety   1027\n",
      "10      customer satisfaction    886\n",
      "11       management committee    836\n",
      "12             greenhouse gas    745\n",
      "13         quality management    726\n",
      "14               code conduct    609\n",
      "15          health management    607\n",
      "16      compliance management    551\n",
      "17        consumer protection    529\n",
      "18        business management    489\n",
      "19        management business    487\n"
     ]
    }
   ],
   "source": [
    "#bigram topicmodeling\n",
    "\n",
    "vocab=word_corpus(full_gram)\n",
    "\n",
    "# 전체 워드의 빈도 계수 \n",
    "df_corpus=pd.DataFrame(columns=[\"text\",\"count\"])\n",
    "tmp_list=[]\n",
    "tmp_list1=[]\n",
    "for word, num in vocab:\n",
    "    tmp_list.append(word)\n",
    "    tmp_list1.append(num)\n",
    "df_corpus['text']=tmp_list\n",
    "df_corpus['count']=tmp_list1\n",
    "#상위 20개의 워드 카운드 계수만 출력\n",
    "print(df_corpus.head(20))\n",
    "\n",
    "# 토픽 모델링 딕셔너리 생성\n",
    "id2word = corpora.Dictionary(full_gram)\n",
    " \n",
    "# 토픽모델링에 사용할 말뭉치 생성\n",
    "texts = full_gram\n",
    " \n",
    "# 용어-문서 빈도\n",
    "corpus = [id2word.doc2bow(text) for text in texts]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "31b7642c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Result\\\\나눔\"topic_result1122\\\\.xlsx'"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.path.join(a+b+c,\".xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "e7d0fc3c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "토픽 기본 모델링을 실시 합니다. 해당 모델은 \"lda_model\" 변수로 입력됩니다.\n",
      " \n",
      "토픽의 개수를 입력해 주세요. 7\n",
      "출력할 토픽별 단어의 개수를 입력해 주세요 10\n",
      "선택한 토픽 모델을 저장하시겠습니까? \n",
      "0 저장  \n",
      "1 미저장  0\n",
      "[(0,\n",
      "  '0.000*\"reductionefficiency program\" + 0.000*\"recruitment cooperation\" + '\n",
      "  '0.000*\"research teamwater\" + 0.000*\"research roadmap\" + 0.000*\"research '\n",
      "  'iso\" + 0.000*\"reputation result\" + 0.000*\"relationship sup\" + '\n",
      "  '0.000*\"relationship feedback\" + 0.000*\"researchcertification institution\" + '\n",
      "  '0.000*\"rate currency\"'),\n",
      " (1,\n",
      "  '0.000*\"reductionefficiency program\" + 0.000*\"recruitment cooperation\" + '\n",
      "  '0.000*\"research teamwater\" + 0.000*\"research roadmap\" + 0.000*\"research '\n",
      "  'iso\" + 0.000*\"reputation result\" + 0.000*\"relationship sup\" + '\n",
      "  '0.000*\"relationship feedback\" + 0.000*\"researchcertification institution\" + '\n",
      "  '0.000*\"rate currency\"'),\n",
      " (2,\n",
      "  '0.000*\"reductionefficiency program\" + 0.000*\"recruitment cooperation\" + '\n",
      "  '0.000*\"research teamwater\" + 0.000*\"research roadmap\" + 0.000*\"research '\n",
      "  'iso\" + 0.000*\"reputation result\" + 0.000*\"relationship sup\" + '\n",
      "  '0.000*\"relationship feedback\" + 0.000*\"researchcertification institution\" + '\n",
      "  '0.000*\"rate currency\"'),\n",
      " (3,\n",
      "  '0.005*\"information security\" + 0.004*\"information protection\" + '\n",
      "  '0.004*\"supply chain\" + 0.004*\"customer satisfaction\" + '\n",
      "  '0.002*\"sustainability management\" + 0.002*\"quality management\" + '\n",
      "  '0.002*\"consumer protection\" + 0.002*\"code conduct\" + 0.002*\"asset '\n",
      "  'management\" + 0.002*\"value creation\"'),\n",
      " (4,\n",
      "  '0.000*\"reductionefficiency program\" + 0.000*\"recruitment cooperation\" + '\n",
      "  '0.000*\"research teamwater\" + 0.000*\"research roadmap\" + 0.000*\"research '\n",
      "  'iso\" + 0.000*\"reputation result\" + 0.000*\"relationship sup\" + '\n",
      "  '0.000*\"relationship feedback\" + 0.000*\"researchcertification institution\" + '\n",
      "  '0.000*\"rate currency\"'),\n",
      " (5,\n",
      "  '0.017*\"risk management\" + 0.006*\"management committee\" + 0.004*\"compliance '\n",
      "  'management\" + 0.004*\"management risk\" + 0.003*\"management management\" + '\n",
      "  '0.003*\"recommendation committee\" + 0.002*\"committee committee\" + '\n",
      "  '0.002*\"marine insurance\" + 0.002*\"committee director\" + 0.002*\"management '\n",
      "  'compliance\"'),\n",
      " (6,\n",
      "  '0.010*\"safety health\" + 0.006*\"safety management\" + 0.006*\"climate change\" '\n",
      "  '+ 0.004*\"health safety\" + 0.004*\"sustainability management\" + '\n",
      "  '0.004*\"greenhouse gas\" + 0.003*\"management management\" + 0.003*\"environment '\n",
      "  'safety\" + 0.003*\"health management\" + 0.002*\"risk management\"')]\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'Result/나눔/topic_result_1122_7\\\\.lda.state'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\gensim\\utils.py\u001b[0m in \u001b[0;36msave\u001b[1;34m(self, fname_or_handle, separately, sep_limit, ignore, pickle_protocol)\u001b[0m\n\u001b[0;32m    763\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 764\u001b[1;33m             \u001b[0m_pickle\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdump\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfname_or_handle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mprotocol\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mpickle_protocol\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    765\u001b[0m             \u001b[0mlogger\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"saved %s object\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__class__\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: file must have a 'write' attribute",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-106-1b6610a7f9d9>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     31\u001b[0m \u001b[1;31m# 모델 저장\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     32\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0msave_lda_model\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 33\u001b[1;33m     \u001b[0mlda_model\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msave\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodelname\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m\".lda\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\gensim\\models\\ldamodel.py\u001b[0m in \u001b[0;36msave\u001b[1;34m(self, fname, ignore, separately, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1582\u001b[0m         \"\"\"\n\u001b[0;32m   1583\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstate\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1584\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstate\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msave\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mutils\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msmart_extension\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'.state'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1585\u001b[0m         \u001b[1;31m# Save the dictionary separately if not in 'ignore'.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1586\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;34m'id2word'\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mignore\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\gensim\\utils.py\u001b[0m in \u001b[0;36msave\u001b[1;34m(self, fname_or_handle, separately, sep_limit, ignore, pickle_protocol)\u001b[0m\n\u001b[0;32m    765\u001b[0m             \u001b[0mlogger\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"saved %s object\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__class__\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    766\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# `fname_or_handle` does not have write attribute\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 767\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_smart_save\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfname_or_handle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mseparately\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msep_limit\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mignore\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpickle_protocol\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mpickle_protocol\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    768\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    769\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\gensim\\utils.py\u001b[0m in \u001b[0;36m_smart_save\u001b[1;34m(self, fname, separately, sep_limit, ignore, pickle_protocol)\u001b[0m\n\u001b[0;32m    609\u001b[0m         )\n\u001b[0;32m    610\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 611\u001b[1;33m             \u001b[0mpickle\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mprotocol\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mpickle_protocol\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    612\u001b[0m         \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    613\u001b[0m             \u001b[1;31m# restore attribs handled specially\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\gensim\\utils.py\u001b[0m in \u001b[0;36mpickle\u001b[1;34m(obj, fname, protocol)\u001b[0m\n\u001b[0;32m   1437\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1438\u001b[0m     \"\"\"\n\u001b[1;32m-> 1439\u001b[1;33m     \u001b[1;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'wb'\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mfout\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# 'b' for binary, needed on Windows\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1440\u001b[0m         \u001b[0m_pickle\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdump\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfout\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mprotocol\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mprotocol\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1441\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\smart_open\\smart_open_lib.py\u001b[0m in \u001b[0;36mopen\u001b[1;34m(uri, mode, buffering, encoding, errors, newline, closefd, opener, ignore_ext, compression, transport_params)\u001b[0m\n\u001b[0;32m    186\u001b[0m         \u001b[0mtransport_params\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m{\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    187\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 188\u001b[1;33m     fobj = _shortcut_open(\n\u001b[0m\u001b[0;32m    189\u001b[0m         \u001b[0muri\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    190\u001b[0m         \u001b[0mmode\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\smart_open\\smart_open_lib.py\u001b[0m in \u001b[0;36m_shortcut_open\u001b[1;34m(uri, mode, compression, buffering, encoding, errors, newline)\u001b[0m\n\u001b[0;32m    359\u001b[0m         \u001b[0mopen_kwargs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'errors'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    360\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 361\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0m_builtin_open\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlocal_path\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbuffering\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mbuffering\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mopen_kwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    362\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    363\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'Result/나눔/topic_result_1122_7\\\\.lda.state'"
     ]
    }
   ],
   "source": [
    "\n",
    "print('토픽 기본 모델링을 실시 합니다. 해당 모델은 \"lda_model\" 변수로 입력됩니다.')\n",
    "print(' ')\n",
    "\n",
    "NUM_TOPICS = int(input('토픽의 개수를 입력해 주세요. '))\n",
    "TOPICS_W_NUM = int(input('출력할 토픽별 단어의 개수를 입력해 주세요 '))\n",
    "save_lda_model= int(input(\"선택한 토픽 모델을 저장하시겠습니까? \\n0 저장  \\n1 미저장  \"))\n",
    "\n",
    "RANDOM_STATE = 100\n",
    "UPDATE_EVERY = 1\n",
    "CHUNKSIZE = 100\n",
    "PASSES = 10\n",
    "ALPHA = 'auto'\n",
    "PER_WORD_TOPICS = True\n",
    "\n",
    "#아래 셀은 토픽모델링(LDA)에 대해 모델을 정의하는 셀이에요.\n",
    "lda_model = gensim.models.ldamodel.LdaModel(corpus=corpus, id2word=id2word, \n",
    "                                            num_topics=NUM_TOPICS, random_state=RANDOM_STATE, \n",
    "                                            update_every=UPDATE_EVERY, chunksize=CHUNKSIZE,\n",
    "                                            passes=PASSES, alpha=ALPHA, per_word_topics=PER_WORD_TOPICS)\n",
    "\n",
    "# 토픽 출력\n",
    "pprint(lda_model.print_topics(num_words=TOPICS_W_NUM))\n",
    "doc_lda = lda_model[corpus]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "model = 'Result/나눔/topic_result_'\n",
    "date = '1122_'\n",
    "modelname = model + str(date) + str(NUM_TOPICS)\n",
    "# 모델 저장 \n",
    "if save_lda_model == 0:\n",
    "    lda_model.save(os.path.join(modelname,\".lda\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d4e0a08",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perplexity \n",
    "print('\\nPerplexity: ', lda_model.log_perplexity(corpus)) # a measure of how good the model is. lower the better.\n",
    " \n",
    "# # Coherence Score\n",
    "# coherence_model_lda = CoherenceModel(model=lda_model, texts=result_data, dictionary=id2word, coherence='c_v')\n",
    "# coherence_lda = coherence_model_lda.get_coherence()\n",
    "# print('\\nCoherence Score: ', coherence_lda)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f826214",
   "metadata": {},
   "outputs": [],
   "source": [
    "for topic_id in range(NUM_TOPICS):\n",
    "    topic_word_probs = lda_model.show_topic(topic_id, TOPICS_W_NUM)\n",
    "    print(\"Topic ID: {}\".format(topic_id))\n",
    "\n",
    "    for topic_word, prob in topic_word_probs:\n",
    "        print(\"\\t{}\\t{}\".format(topic_word, prob))\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0345135a",
   "metadata": {},
   "outputs": [],
   "source": [
    "name=modelname+'.html'\n",
    "def create_vis(model):\n",
    "    pyLDAvis.enable_notebook()\n",
    "    vis = pyLDAvis.gensim_models.prepare(model, corpus, id2word, mds='mmds')\n",
    "    pyLDAvis.save_html(vis, name)\n",
    "    return vis\n",
    "#lda_model or optimal_model\n",
    "create_vis(lda_model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a217cabf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 위에서 선택한 토픽 모델을 엑셀 파일로 떨어뜨리기 위한 함수 \n",
    "def format_topics_sentences(ldamodel=lda_model, corpus=corpus, texts=result_data):\n",
    "    sent_topics_df = pd.DataFrame()\n",
    "    for i, row in enumerate(ldamodel[corpus]):\n",
    "        topics_info_by_doc = row[0]\n",
    "        topics_info_by_doc = sorted(topics_info_by_doc, key=lambda x: (x[1]), reverse=True)\n",
    "        for j, (topic_num, prop_topic) in enumerate(topics_info_by_doc):\n",
    "            if j == 0:  # => dominant topic\n",
    "                wp = ldamodel.show_topic(topic_num)\n",
    "                topic_keywords = \", \".join([word for word, prop in wp])\n",
    "                sent_topics_df = sent_topics_df.append(pd.Series([int(topic_num), round(prop_topic, 4), topic_keywords]),\n",
    "                                                       ignore_index=True)\n",
    "            else:\n",
    "                break\n",
    "\n",
    "    sent_topics_df.columns = ['Dominant_Topic', 'Perc_Contribution', 'Topic_Keywords']\n",
    "\n",
    "    contents = pd.Series(texts)\n",
    "    sent_topics_df = pd.concat([sent_topics_df, contents], axis=1)\n",
    "    return(sent_topics_df)\n",
    "\n",
    "\n",
    "'''\n",
    "확인하고자 하는 모델을 입력하여 데이터 프레임으로 만든 후, 최종 엑셀파일을 저장합니다.\n",
    "'''\n",
    "\n",
    "df_topic_sents_keywords = format_topics_sentences(ldamodel=lda_model, corpus=corpus, texts=result_data)\n",
    "topic_weight=lda_model[corpus]\n",
    "df_topic_weight = pd.DataFrame()\n",
    "for i in range(1, lda_model.num_topics+1):\n",
    "    df_topic_weight['topic{}'.format(i)]=pd.Series()\n",
    "\n",
    "\n",
    "# Format\n",
    "df_dominant_topic = df_topic_sents_keywords.reset_index()\n",
    "df_dominant_topic.columns = ['Document_No', 'Dominant_Topic', 'Topic_Perc_Contrib', 'Keywords', 'Text']\n",
    " \n",
    "\n",
    "# LDA모델에서 토픽 웨이트를 추출하여 데이터 프레임에 저장 \n",
    "for num, topic in enumerate(topic_weight):\n",
    "    for i in topic[0]:\n",
    "        df_topic_weight.loc[num, 'topic' + str(i[0]+1)] = i[1]\n",
    "\n",
    "# Null값은 아주 작은 값으로 대체\n",
    "df_topic_weight = df_topic_weight.fillna(math.exp(-1000)) \n",
    "\n",
    "#데이터 프레임 연결\n",
    "df_topic_last = pd.concat([DF_raw, df_dominant_topic, df_topic_weight], axis=1)\n",
    "print(df_topic_last)\n",
    "\n",
    "# 마지막 엑셀 저장\n",
    "df_topic_last.to_excel(RESULT_TOPIC_EXCEL,sheet_name = \"sheet1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "cd3dfa18",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_excel('./Data/1122전처리본.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "961c17ed",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
